import cv2
import sys
import os

import numpy as np
from PIL import Image
import hashlib
from typing import List, Tuple, Dict, Optional, Union



import torch
from yolo_cam.eigen_cam import EigenCAM as YOLO_EigenCAM
from yolo_cam.utils.image import scale_cam_image as scale_yolocam_image

from scipy import ndimage
from scipy.stats import entropy
from skimage.measure import shannon_entropy

from datetime import datetime


class XAIAnalyzer:
    """XAI (Explainable AI) ë¶„ì„ì„ ìœ„í•œ í´ë˜ìŠ¤ - CAM, GradCAM ë“± ì§€ì›"""
    
    def __init__(self, device: Optional[str] = None, model_path: Optional[str] = None):
        """
        XAI ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
        """
        if device is None:
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        self.model = None
        self.model_path = model_path
        self.model_name = None
        self.class_names = {}
        self.feature_maps = None
        self.gradients = None
        self.target_layers = None  # íƒ€ê²Ÿ ë ˆì´ì–´ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì¶”ê°€
        self.target_layer_index = None  # íƒ€ê²Ÿ ë ˆì´ì–´ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì¶”ê°€
        
        # print(f"Using device: {self.device}")
    
    def load_model(self, model_path: str, target_layer_index: Optional[int] = None):
        """
        YOLO ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        try:
            from ultralytics import YOLO
            
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"Model file not found: {model_path}")
            
            self.model = YOLO(model_path)
            self.model_name = os.path.basename(model_path)
            
            # ëª¨ë¸ì„ ì§€ì •ëœ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model.to(self.device)
            
            # í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°
            if hasattr(self.model, 'names'):
                self.class_names = self.model.names

            # íƒ€ê²Ÿ ë ˆì´ì–´ ì°¾ê¸°
            self.target_layers = self.find_target_layer(target_layer_index=target_layer_index)

            print(f"Model loaded successfully: {self.model_name}")
            print(f"Number of classes: {len(self.class_names)}")
            
            if self.target_layers:
                print(f"Target layer found: {self.target_layer_index}")
            
        except ImportError:
            print("Error: ultralytics package not found. Please install it with: pip install ultralytics")
            raise
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    
    def parse_detections(self, results) -> Tuple[np.ndarray, List, List]:
        """
        YOLO ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë°•ìŠ¤, ìƒ‰ìƒ, í´ë˜ìŠ¤ëª…ìœ¼ë¡œ íŒŒì‹±
        
        Args:
            results: YOLO ëª¨ë¸ì˜ ì¶”ë¡  ê²°ê³¼
            
        Returns:
            Tuple[np.ndarray, List, List]: (boxes, colors, names)
        """
        boxes = []
        colors = []
        names = []
        
        if not results or len(results) == 0:
            return np.array([]), [], []
        
        for result in results[0].boxes:
            box = result.xyxy[0].cpu().numpy()  # x1, y1, x2, y2 í˜•ì‹
            conf = float(result.conf)
            cls = int(result.cls)
            name = results[0].names[cls]
            
            boxes.append(box)
            colors.append(self._generate_color(cls))  # í´ë˜ìŠ¤ë³„ ê³ ìœ  ìƒ‰ìƒ
            names.append(f"{name} {conf:.2f}")
        
        return np.array(boxes), colors, names
    
    def _generate_color(self, class_id: int) -> List[int]:
        """
        í´ë˜ìŠ¤ IDì— ë”°ë¥¸ ê³ ìœ í•œ ìƒ‰ìƒ ìƒì„±
        
        Args:
            class_id: í´ë˜ìŠ¤ ID
            
        Returns:
            List[int]: RGB ìƒ‰ìƒ ê°’ [R, G, B]
        """
        np.random.seed(class_id)
        color = np.random.randint(0, 255, size=3).tolist()
        return color
    
    def draw_detections(self, boxes: np.ndarray, colors: List, names: List, image: np.ndarray) -> np.ndarray:
        """
        ê²€ì¶œ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ì‹œê°í™”
        
        Args:
            boxes: ê²€ì¶œëœ ë°•ìŠ¤ ì¢Œí‘œ
            colors: ê° ë°•ìŠ¤ì˜ ìƒ‰ìƒ
            names: ê° ë°•ìŠ¤ì˜ í´ë˜ìŠ¤ëª…ê³¼ ì‹ ë¢°ë„
            image: ì›ë³¸ ì´ë¯¸ì§€
            
        Returns:
            np.ndarray: ì‹œê°í™”ëœ ì´ë¯¸ì§€
        """
        image_copy = image.copy()
        
        for box, color, name in zip(boxes, colors, names):
            x1, y1, x2, y2 = map(int, box)
            
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(image_copy, (x1, y1), (x2, y2), color, 2)
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
            (text_w, text_h), _ = cv2.getTextSize(name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(image_copy, (x1, y1-text_h-4), (x1+text_w, y1), color, -1)
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            cv2.putText(image_copy, name, (x1, y1-4), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)
        
        return image_copy
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """
        ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Failed to load image: {image_path}")
        
        return image
    
    def calculate_file_hash(self, file_path: str) -> str:
        """
        íŒŒì¼ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: MD5 í•´ì‹œê°’
        """
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            buf = f.read()
            hasher.update(buf)
        return hasher.hexdigest()
    
    def get_model_info(self) -> Dict:
        """
        í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict: ëª¨ë¸ ì •ë³´
        """
        if self.model is None:
            return {}
        
        info = {
            'model_name': self.model_name,
            'device': str(self.device),
            'num_classes': len(self.class_names),
            'class_names': self.class_names.copy(),
            'target_layer': str(self.target_layers) if self.target_layers else None,
            'target_layer_index': self.target_layer_index
        }
        
        return info
    
    def list_model_layers(self) -> List[Dict]:
        """
        ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: ë ˆì´ì–´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if self.model is None:
            print("Model not loaded. Please load model first.")
            return []
        
        model_layers = self.model.model.model
        layers_info = []
        
        for idx, layer in enumerate(model_layers):
            layer_info = {
                'index': idx,
                'type': type(layer).__name__,
                'str': str(layer),
                'is_target': idx == self.target_layer_index if self.target_layer_index is not None else False
            }
            layers_info.append(layer_info)
        
        return layers_info
    
    def print_model_layers(self):
        """
        ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        """
        layers_info = self.list_model_layers()
        if not layers_info:
            return
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ MODEL LAYERS INFORMATION")
        print("=" * 80)
        print(f"{'Index':<6} {'Type':<20} {'Description':<50}")
        print("-" * 80)
        
        for layer_info in layers_info:
            marker = " ğŸ‘ˆ" if layer_info['is_target'] else ""
            print(f"{layer_info['index']:<6} {layer_info['type']:<20} {layer_info['str'][:47]:<47}{marker}")
        
        print("=" * 80)
        print("ğŸ’¡ Use --target-layer <index> to specify a different target layer")
        print("ğŸ’¡ Recommended layers are usually Conv2d or BatchNorm2d layers")
        print("=" * 80)
    
    def find_target_layer(self, target_layer_index: Optional[int] = None) -> Optional[torch.nn.Module]:
        """
        YOLO ëª¨ë¸ì—ì„œ CAM ë¶„ì„ì— ì í•©í•œ íƒ€ê²Ÿ ë ˆì´ì–´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            target_layer_index: íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë ˆì´ì–´ ì‚¬ìš© (0ë¶€í„° ì‹œì‘)
            
        Returns:
            Optional[torch.nn.Module]: íƒ€ê²Ÿ ë ˆì´ì–´ ë˜ëŠ” None
        """
        if self.model is None:
            print("Model not loaded. Please load model first.")
            return None
        
        target_layer = None
        model_layers = self.model.model.model
        
        # ì‚¬ìš©ìê°€ íŠ¹ì • ì¸ë±ìŠ¤ë¥¼ ì§€ì •í•œ ê²½ìš°
        if target_layer_index is not None:
            if 0 <= target_layer_index < len(model_layers):
                target_layer = model_layers[target_layer_index]
                self.target_layer_index = target_layer_index  # ì¸ë±ìŠ¤ ì €ì¥
                print(f"ì‚¬ìš©ì ì§€ì • ì¸ë±ìŠ¤ {target_layer_index}ì˜ ë ˆì´ì–´ ì‚¬ìš©: {target_layer}")
                return target_layer
            else:
                print(f"ì¸ë±ìŠ¤ {target_layer_index}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (0-{len(model_layers)-1} ë²”ìœ„)")
                return None
        
        # ìë™ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
        print("ìë™ìœ¼ë¡œ ì í•©í•œ íƒ€ê²Ÿ ë ˆì´ì–´ë¥¼ ì°¾ìŠµë‹ˆë‹¤...")
        
        # ëª¨ë¸ì˜ ë ˆì´ì–´ë“¤ì„ ì—­ìˆœìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ concat() ë ˆì´ì–´ ì°¾ê¸°
        for idx, layers in reversed(list(enumerate(model_layers))):
            if str(layers).lower() == "concat()":
                print(f"ë§ˆì§€ë§‰ concat()ì˜ ì¸ë±ìŠ¤: {idx}")
                print(f"ë§ˆì§€ë§‰ concat() ëª¨ë¸: {layers}")
                target_layer = layers
                self.target_layer_index = idx  # ì¸ë±ìŠ¤ ì €ì¥
                break
        else:
            print("concat()ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ ë ˆì´ì–´ ì‚¬ìš©
            target_layer = model_layers[-2]
            self.target_layer_index = len(model_layers) - 2  # ì¸ë±ìŠ¤ ì €ì¥
            print(f"ê¸°ë³¸ íƒ€ê²Ÿ ë ˆì´ì–´ ì‚¬ìš©: {target_layer}")
        
        return target_layer
    
    def get_target_layers(self, target_layer_index: Optional[int] = None) -> Optional[List]:
        """
        íƒ€ê²Ÿ ë ˆì´ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì§€ì •í•œ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë ˆì´ì–´ë¥¼, ì—†ìœ¼ë©´ ì €ì¥ëœ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            target_layer_index: íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë ˆì´ì–´ ì‚¬ìš© (0ë¶€í„° ì‹œì‘)
            
        Returns:
            Optional[List]: íƒ€ê²Ÿ ë ˆì´ì–´ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        if self.model is None:
            print("Model not loaded. Please load model first.")
            return None
        
        # ì €ì¥ëœ íƒ€ê²Ÿ ë ˆì´ì–´ ì‚¬ìš©
        if self.target_layers is None:
            print("Target layers not found. Please load model first.")
            return None
        
        return [self.target_layers]
    
    def generate_cam(self, image_path: str, target_layers: Optional[List] = None, 
                    target_layer_index: Optional[int] = None, use_rgb: bool = True) -> Dict:
        """
        ì´ë¯¸ì§€ì— ëŒ€í•´ CAM (Class Activation Mapping)ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            target_layers: CAM ë¶„ì„ì— ì‚¬ìš©í•  íƒ€ê²Ÿ ë ˆì´ì–´ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ ì„ íƒ)
            target_layer_index: íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë ˆì´ì–´ ì‚¬ìš© (0ë¶€í„° ì‹œì‘)
            use_rgb: RGB ì´ë¯¸ì§€ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            Dict: CAM ë¶„ì„ ê²°ê³¼
        """
        if self.model is None:
            raise ValueError("Model not loaded. Please load model first.")
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            rgb_img = self.preprocess_image(image_path)
            img = np.float32(rgb_img) / 255
            
            # íƒ€ê²Ÿ ë ˆì´ì–´ ì„¤ì •
            if target_layers is None:
                target_layers = self.get_target_layers(target_layer_index)
                if target_layers is None:
                    raise ValueError("Could not find suitable target layer")
            
            # YOLO_EigenCAM ìƒì„±
            cam = YOLO_EigenCAM(self.model, target_layers, task='od')
            
            # CAM ìƒì„±
            cam_result_raw = cam(rgb_img)
            print(f"    ğŸ” CAM raw result type: {type(cam_result_raw)}")
            print(f"    ğŸ” CAM raw result shape: {getattr(cam_result_raw, 'shape', 'No shape attribute')}")
            
            # cam_result_raw ì²˜ë¦¬ - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
            if isinstance(cam_result_raw, tuple):
                cam_result_processed = cam_result_raw[0]
            elif isinstance(cam_result_raw, list):
                cam_result_processed = cam_result_raw[0] if len(cam_result_raw) > 0 else cam_result_raw
            else:
                cam_result_processed = cam_result_raw
                
            # cam_result_processedê°€ ì—¬ì „íˆ listì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
            if isinstance(cam_result_processed, list) and len(cam_result_processed) > 0:
                cam_result_processed = cam_result_processed[0]
                
            print(f"    ğŸ” CAM processed result type: {type(cam_result_processed)}")
            print(f"    ğŸ” CAM processed result shape: {getattr(cam_result_processed, 'shape', 'No shape attribute')}")
            
            # ìµœì¢… CAM ë°ì´í„° ì¶”ì¶œ
            if hasattr(cam_result_processed, 'shape') and len(cam_result_processed.shape) >= 2:
                grayscale_cam = cam_result_processed[0, :, :] if len(cam_result_processed.shape) > 2 else cam_result_processed
            else:
                raise ValueError(f"Unexpected CAM result format: {type(cam_result_processed)}")
            
            # ë””ë²„ê¹…: CAM ë°ì´í„° ì •ë³´ ì¶œë ¥
            print(f"    ğŸ” Generated CAM data: shape={grayscale_cam.shape}, dtype={grayscale_cam.dtype}")
            print(f"    ğŸ” CAM data stats: min={grayscale_cam.min():.6f}, max={grayscale_cam.max():.6f}, mean={grayscale_cam.mean():.6f}")
            
            # ê²°ê³¼ ì €ì¥ (ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥, ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì œì™¸)
            result = {
                'grayscale_cam': grayscale_cam,
                'target_layers': [str(layer) for layer in target_layers],
                'image_path': image_path
            }
            
            return result
            
        except Exception as e:
            print(f"Error generating CAM for {image_path}: {e}")
            return None

    
    def calculate_cam_statistics(self, cam: np.ndarray) -> Dict:
        """
        CAM í™œì„±ë„ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            cam: CAM ë°ì´í„° (2D numpy array)
            
        Returns:
            Dict: CAM í†µê³„ ì •ë³´ (ê¸°ë³¸ í†µê³„ + Percentile + Skewness)
        """
        # ê¸°ë³¸ í†µê³„
        cam_stats = {
            'mean': ('í‰ê· ', np.mean(cam)),
            'max': ('ìµœëŒ€ê°’', np.max(cam)),
            'min': ('ìµœì†Œê°’', np.min(cam)),
            'sum': ('í•©ê³„', np.sum(cam)),
            'std': ('í‘œì¤€í¸ì°¨', np.std(cam)),
            'median': ('ì¤‘ì•™ê°’', np.median(cam)),
            'variance': ('ë¶„ì‚°', np.var(cam)),
            'range': ('ë²”ìœ„', np.max(cam) - np.min(cam)),
            'shape': ('í¬ê¸°', cam.shape),
            'total_pixels': ('ì´ í”½ì…€ ìˆ˜', cam.size)
        }
        
        # 0ë³´ë‹¤ í° ê°’ë§Œ ì‚¬ìš© (í™œì„±í™”ëœ ì˜ì—­)
        non_zero_cam = cam[cam > 0]
        
        # Percentile ë¶„ì„
        if len(non_zero_cam) > 0:
            # ë‹¤ì–‘í•œ ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
            percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
            percentile_values = {f'P{p}': np.percentile(non_zero_cam, p) for p in percentiles}
            
            # ì˜ë¯¸ìˆëŠ” ë¹„ìœ¨ ê³„ì‚°
            ratios = {
                'P95_P5_ratio': percentile_values['P95'] / percentile_values['P5'],  # ê·¹ê°’ ë¹„ìœ¨
                'P90_P10_ratio': percentile_values['P90'] / percentile_values['P10'],  # ìƒìœ„/í•˜ìœ„ 10% ë¹„ìœ¨
                'P99_P50_ratio': percentile_values['P99'] / percentile_values['P50'],  # ê·¹ê°’/ì¤‘ì•™ê°’ ë¹„ìœ¨
                'P75_P25_ratio': percentile_values['P75'] / percentile_values['P25'],  # IQR ë¹„ìœ¨
            }
            
            # Percentile í•´ì„ ì •ë³´
            percentile_interpretation = {
                'high_concentration': ratios['P95_P5_ratio'] > 10,  # ê·¹ë„ë¡œ ì§‘ì¤‘
                'moderate_concentration': 5 < ratios['P95_P5_ratio'] <= 10,  # ì ë‹¹íˆ ì§‘ì¤‘
                'low_concentration': ratios['P95_P5_ratio'] <= 5,  # ë¶„ì‚°ë¨
                'no_activation': False
            }
            
            # Percentile ì •ë³´ë¥¼ cam_statsì— ì¶”ê°€
            cam_stats.update({
                'percentiles': percentile_values,
                'percentile_ratios': ratios,
                'percentile_interpretation': percentile_interpretation,
                'total_activated_pixels': len(non_zero_cam),
                'activation_ratio': len(non_zero_cam) / cam.size * 100
            })
            
            # Skewness ë¶„ì„
            if len(non_zero_cam) >= 3:
                mean_val = np.mean(non_zero_cam)
                std_val = np.std(non_zero_cam)
                
                # í‘œì¤€ Skewness ê³„ì‚°
                if std_val > 0:
                    skewness = np.mean(((non_zero_cam - mean_val) / std_val) ** 3)
                else:
                    skewness = 0.0
                
                # Percentile ê¸°ë°˜ Skewness (Bowley's coefficient)
                p10, p50, p90 = np.percentile(non_zero_cam, [10, 50, 90])
                if p90 - p10 > 0:
                    percentile_skewness = (p90 + p10 - 2*p50) / (p90 - p10)
                else:
                    percentile_skewness = 0.0
                
                # Skewness íƒ€ì… ë¶„ë¥˜
                if abs(skewness) < 0.5:
                    skewness_type = 'symmetric'
                    distribution_type = 'ì •ê·œë¶„í¬ì— ê°€ê¹Œì›€'
                elif skewness > 0.5:
                    skewness_type = 'right_skewed'
                    distribution_type = 'ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨ (ë†’ì€ í™œì„±í™” ê°’ì´ ë§ìŒ)'
                else:
                    skewness_type = 'left_skewed'
                    distribution_type = 'ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨ (ë‚®ì€ í™œì„±í™” ê°’ì´ ë§ìŒ)'
                
                # Skewness í•´ì„ ì •ë³´
                skewness_interpretation = {
                    'concentration_level': 'high' if abs(skewness) > 1.0 else 'moderate' if abs(skewness) > 0.5 else 'low',
                    'activation_pattern': 'focused' if skewness > 0.5 else 'distributed' if skewness < -0.5 else 'balanced',
                    'model_behavior': 'selective' if skewness > 1.0 else 'general' if skewness < -0.5 else 'balanced'
                }
                
                # Skewness ì •ë³´ë¥¼ cam_statsì— ì¶”ê°€
                cam_stats.update({
                    'skewness': float(skewness),
                    'percentile_skewness': float(percentile_skewness),
                    'skewness_type': skewness_type,
                    'distribution_type': distribution_type,
                    'skewness_interpretation': skewness_interpretation,
                    'skewness_stats': {
                        'mean': float(mean_val),
                        'median': float(p50),
                        'std': float(std_val),
                        'p10': float(p10),
                        'p90': float(p90)
                    }
                })
            else:
                # ë°ì´í„° ë¶€ì¡± ì‹œ ê¸°ë³¸ê°’
                cam_stats.update({
                    'skewness': 0.0,
                    'percentile_skewness': 0.0,
                    'skewness_type': 'insufficient_data',
                    'distribution_type': 'ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€',
                    'skewness_interpretation': {
                        'concentration_level': 'unknown',
                        'activation_pattern': 'unknown',
                        'model_behavior': 'unknown'
                    },
                    'skewness_stats': {
                        'mean': 0.0,
                        'median': 0.0,
                        'std': 0.0,
                        'p10': 0.0,
                        'p90': 0.0
                    }
                })
        else:
            # í™œì„±í™”ëœ í”½ì…€ì´ ì—†ëŠ” ê²½ìš°
            cam_stats.update({
                'percentiles': {},
                'percentile_ratios': {},
                'percentile_interpretation': {
                    'high_concentration': False,
                    'moderate_concentration': False,
                    'low_concentration': True,
                    'no_activation': True
                },
                'total_activated_pixels': 0,
                'activation_ratio': 0.0,
                'skewness': 0.0,
                'percentile_skewness': 0.0,
                'skewness_type': 'no_activation',
                'distribution_type': 'í™œì„±í™” ì—†ìŒ',
                'skewness_interpretation': {
                    'concentration_level': 'none',
                    'activation_pattern': 'none',
                    'model_behavior': 'none'
                },
                'skewness_stats': {
                    'mean': 0.0,
                    'median': 0.0,
                    'std': 0.0,
                    'p10': 0.0,
                    'p90': 0.0
                }
            })
        
        # ê¸°ì¡´ ì‚¬ë¶„ìœ„ìˆ˜ ì •ë³´ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
        q25, q50, q75 = np.percentile(cam, [25, 50, 75])
        cam_stats.update({
            'q25': ('1ì‚¬ë¶„ìœ„ìˆ˜', q25),
            'q50': ('ì¤‘ì•™ê°’', q50),
            'q75': ('3ì‚¬ë¶„ìœ„ìˆ˜', q75),
            'iqr': ('ì‚¬ë¶„ìœ„ ë²”ìœ„', q75 - q25)
        })
        
        # ìƒìœ„ 10% í™œì„±ë„ ì •ë³´
        threshold_90 = np.percentile(cam, 90)
        high_activation_mask = cam > threshold_90
        cam_stats.update({
            'threshold_90': ('ìƒìœ„ 10% ì„ê³„ê°’', threshold_90),
            'high_activation_pixels': ('ìƒìœ„ 10% í”½ì…€ ìˆ˜', np.sum(high_activation_mask)),
            'high_activation_ratio': ('ìƒìœ„ 10% ë¹„ìœ¨', np.sum(high_activation_mask) / cam.size * 100)
        })
        
        return cam_stats
    

    
    def adaptive_thresholding(self, cam: np.ndarray, percentile: int = 85) -> np.ndarray:
        """
        Adaptive ì“°ë ˆìŠ¤í™€ë”©ì„ ì ìš©í•œ CAMì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            cam: CAM ë°ì´í„°
            percentile: ì„ê³„ê°’ ë°±ë¶„ìœ„ìˆ˜
            
        Returns:
            np.ndarray: Adaptive ì“°ë ˆìŠ¤í™€ë”© ì ìš©ëœ CAM
        """
        threshold = np.percentile(cam, percentile)
        cam_filtered = np.where(cam > threshold, cam, 0)
        
        if cam_filtered.max() > 0:
            adaptive_cam = cam_filtered / cam_filtered.max()
        else:
            adaptive_cam = cam_filtered
        
        return adaptive_cam
    
    def find_optimal_threshold_for_components(self, cam: np.ndarray, percentile_range: tuple = (50, 95)) -> Dict:
        """
        ì»´í¬ë„ŒíŠ¸ ê°œìˆ˜ê°€ ìµœëŒ€ê°€ ë˜ëŠ” ìµœì  ì„ê³„ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            cam: CAM ë°ì´í„°
            percentile_range: íƒìƒ‰í•  ë°±ë¶„ìœ„ìˆ˜ ë²”ìœ„ (min, max)
            
        Returns:
            Dict: ìµœì  ì„ê³„ê°’ ì •ë³´
        """
        min_percentile, max_percentile = percentile_range
        percentiles = range(min_percentile, max_percentile + 1, 5)  # 5% ê°„ê²©ìœ¼ë¡œ íƒìƒ‰
        
        best_num_components = 0
        best_threshold = 0
        best_percentile = 0
        component_counts = []
        
        for percentile in percentiles:
            threshold = np.percentile(cam, percentile)
            binary_mask = cam > threshold
            labeled_mask, num_components = ndimage.label(binary_mask)
            
            component_counts.append(num_components)
            
            if num_components > best_num_components:
                best_num_components = num_components
                best_threshold = threshold
                best_percentile = percentile
        
        return {
            'optimal_percentile': best_percentile,
            'optimal_threshold': best_threshold,
            'max_components': best_num_components,
            'percentiles_tested': list(percentiles),
            'component_counts': component_counts
        }
    
    def analyze_connected_components(self, cam: np.ndarray, threshold_percentile: int = 85) -> Dict:
        """
        Connected Components Analysisë¥¼ í†µí•œ í™œì„±í™” ì˜ì—­ êµ¬ì¡° ë¶„ì„
        
        Args:
            cam: CAM ë°ì´í„°
            threshold_percentile: ì„ê³„ê°’ ë°±ë¶„ìœ„ìˆ˜
            
        Returns:
            Dict: ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ë¶„ì„ ê²°ê³¼
        """
        threshold = np.percentile(cam, threshold_percentile)
        binary_mask = cam > threshold
        
        # ê¸°ë³¸ í™œì„±í™” ì˜ì—­ í†µê³„
        active_pixels = np.sum(binary_mask)
        active_ratio = active_pixels / cam.size * 100
        
        # Connected Components ë¶„ì„
        labeled_mask, num_components = ndimage.label(binary_mask)
        
        result = {
            'threshold': threshold,
            'active_pixels': active_pixels,
            'active_ratio': active_ratio,
            'num_components': num_components,
            'binary_mask': binary_mask,
            'labeled_mask': labeled_mask
        }
        
        if num_components > 0:
            # ê° ì»´í¬ë„ŒíŠ¸ ë¶„ì„
            component_sizes = []
            component_centroids = []
            component_bboxes = []
            component_densities = []
            circularities = []
            
            for i in range(1, num_components + 1):
                component_mask = labeled_mask == i
                size = np.sum(component_mask)
                component_sizes.append(size)
                
                # ì¤‘ì‹¬ì  ê³„ì‚°
                y_coords, x_coords = np.where(component_mask)
                centroid_y = np.mean(y_coords)
                centroid_x = np.mean(x_coords)
                component_centroids.append((centroid_x, centroid_y))
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                min_y, max_y = np.min(y_coords), np.max(y_coords)
                min_x, max_x = np.min(x_coords), np.max(x_coords)
                bbox_area = (max_y - min_y + 1) * (max_x - min_x + 1)
                component_bboxes.append((min_x, min_y, max_x, max_y))
                component_densities.append(size / bbox_area)
                
                # ì›í˜•ë„ ê³„ì‚°
                contours, _ = cv2.findContours(component_mask.astype(np.uint8), 
                                             cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    contour = contours[0]
                    area = cv2.contourArea(contour)
                    perimeter = cv2.arcLength(contour, True)
                    if perimeter > 0:
                        circularity = 4 * np.pi * area / (perimeter ** 2)
                        circularities.append(circularity)
                    else:
                        circularities.append(0)
                else:
                    circularities.append(0)
            
            result.update({
                'component_sizes': np.array(component_sizes),
                'component_centroids': component_centroids,
                'component_bboxes': component_bboxes,
                'component_densities': np.array(component_densities),
                'circularities': np.array(circularities),
                'size_stats': {
                    'max': np.max(component_sizes),
                    'min': np.min(component_sizes),
                    'mean': np.mean(component_sizes),
                    'median': np.median(component_sizes),
                    'std': np.std(component_sizes)
                }
            })
        
        return result
    
    def calculate_cam_centroids(self, cam: np.ndarray, methods: List[str] = None) -> Dict:
        """
        CAMì˜ centroid ì¢Œí‘œë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ê³„ì‚°í•˜ê³  confidence scoreë„ í•¨ê»˜ ì œê³µ
        
        Args:
            cam: CAM ë°ì´í„°
            methods: ì‚¬ìš©í•  ë°©ë²• ë¦¬ìŠ¤íŠ¸ ['weighted', 'threshold', 'max', 'components']
            
        Returns:
            Dict: ê° ë°©ë²•ë³„ centroid ì¢Œí‘œì™€ confidence score
        """
        if methods is None:
            methods = ['weighted', 'threshold', 'max', 'components']
        
        centroids = {}
        
        # 1. í™œì„±ë„ ê°€ì¤‘ í‰ê·  centroid
        if 'weighted' in methods:
            y_coords, x_coords = np.meshgrid(np.arange(cam.shape[0]), np.arange(cam.shape[1]), indexing='ij')
            total_weight = np.sum(cam)
            if total_weight > 0:
                weighted_x = np.sum(x_coords * cam) / total_weight
                weighted_y = np.sum(y_coords * cam) / total_weight
                
                # Confidence: ì „ì²´ í™œì„±í™” ê°•ë„ ëŒ€ë¹„ í‰ê·  í™œì„±í™” ê°•ë„
                # ë†’ì€ ê°’ = í™œì„±í™”ê°€ ì§‘ì¤‘ë˜ì–´ ìˆìŒ, ë‚®ì€ ê°’ = í™œì„±í™”ê°€ ë¶„ì‚°ë˜ì–´ ìˆìŒ
                mean_activation = np.mean(cam)
                max_activation = np.max(cam)
                confidence = mean_activation / max_activation if max_activation > 0 else 0
            else:
                weighted_x, weighted_y = cam.shape[1] / 2, cam.shape[0] / 2
                confidence = 0
            
            centroids['weighted'] = {
                'x': weighted_x,
                'y': weighted_y,
                'confidence': confidence,
                'description': 'Weighted average based on activation intensity'
            }
        
        # 2. ì„ê³„ê°’ ê¸°ë°˜ centroid
        if 'threshold' in methods:
            threshold = np.percentile(cam, 85)
            active_mask = cam > threshold
            if np.sum(active_mask) > 0:
                y_coords, x_coords = np.where(active_mask)
                threshold_x = np.mean(x_coords)
                threshold_y = np.mean(y_coords)
                
                # Confidence: ì„ê³„ê°’ ì´ìƒ í™œì„±í™”ëœ ì˜ì—­ì˜ ë¹„ìœ¨ê³¼ ê°•ë„
                # ë†’ì€ ê°’ = ëª…í™•í•œ í™œì„±í™” ì˜ì—­, ë‚®ì€ ê°’ = íë¦¿í•œ í™œì„±í™” íŒ¨í„´
                active_ratio = np.sum(active_mask) / cam.size
                active_intensity = np.mean(cam[active_mask]) / np.max(cam) if np.max(cam) > 0 else 0
                confidence = active_ratio * active_intensity
            else:
                threshold_x, threshold_y = cam.shape[1] / 2, cam.shape[0] / 2
                confidence = 0
            
            centroids['threshold'] = {
                'x': threshold_x,
                'y': threshold_y,
                'confidence': confidence,
                'description': 'Centroid of pixels above 85th percentile threshold'
            }
        
        # 3. ìµœëŒ€ í™œì„±ë„ ìœ„ì¹˜
        if 'max' in methods:
            max_idx = np.unravel_index(np.argmax(cam), cam.shape)
            max_y, max_x = max_idx
            
            # Confidence: ìµœëŒ€ê°’ê³¼ í‰ê· ê°’ì˜ ì°¨ì´ (í”¼í¬ì˜ ë¾°ì¡±í•¨)
            # ë†’ì€ ê°’ = ëšœë ·í•œ í”¼í¬, ë‚®ì€ ê°’ = í‰í‰í•œ í™œì„±í™” íŒ¨í„´
            max_val = np.max(cam)
            mean_val = np.mean(cam)
            confidence = (max_val - mean_val) / max_val if max_val > 0 else 0
            
            centroids['max'] = {
                'x': max_x,
                'y': max_y,
                'confidence': confidence,
                'description': 'Location of maximum activation value'
            }
        
        # 4. Connected Components ê¸°ë°˜ centroid
        if 'components' in methods:
            threshold = np.percentile(cam, 85)
            binary_mask = cam > threshold
            labeled_mask, num_components = ndimage.label(binary_mask)
            
            if num_components > 0:
                component_sizes = []
                component_centroids = []
                
                for i in range(1, num_components + 1):
                    component_mask = labeled_mask == i
                    size = np.sum(component_mask)
                    component_sizes.append(size)
                    
                    y_coords, x_coords = np.where(component_mask)
                    centroid_y = np.mean(y_coords)
                    centroid_x = np.mean(x_coords)
                    component_centroids.append((centroid_x, centroid_y))
                
                largest_idx = np.argmax(component_sizes)
                largest_x, largest_y = component_centroids[largest_idx]
                
                # Confidence: ê°€ì¥ í° ì—°ê²° ì»´í¬ë„ŒíŠ¸ì˜ ë¹„ìœ¨
                # ë†’ì€ ê°’ = í•˜ë‚˜ì˜ í° í™œì„±í™” ì˜ì—­, ë‚®ì€ ê°’ = ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í™œì„±í™” ì˜ì—­
                total_active_pixels = np.sum(binary_mask)
                largest_component_size = component_sizes[largest_idx]
                confidence = largest_component_size / total_active_pixels if total_active_pixels > 0 else 0
            else:
                largest_x, largest_y = cam.shape[1] / 2, cam.shape[0] / 2
                confidence = 0
            
            centroids['components'] = {
                'x': largest_x,
                'y': largest_y,
                'confidence': confidence,
                'description': 'Centroid of largest connected component'
            }
        
        return centroids
    
    def calculate_cam_entropy(self, cam: np.ndarray, methods: List[str] = None) -> Dict:
        """
        CAM ë°ì´í„°ì˜ ë‹¤ì–‘í•œ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        
        Args:
            cam: CAM ë°ì´í„°
            methods: ì‚¬ìš©í•  ì—”íŠ¸ë¡œí”¼ ë°©ë²• ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Dict: ì—”íŠ¸ë¡œí”¼ ë¶„ì„ ê²°ê³¼
        """
        if methods is None:
            methods = ['shannon', 'spatial', 'histogram', 'conditional']
        
        entropy_results = {}
        
        # 1. Shannon ì—”íŠ¸ë¡œí”¼
        if 'shannon' in methods:
            cam_normalized = (cam - cam.min()) / (cam.max() - cam.min())
            cam_discrete = (cam_normalized * 255).astype(np.uint8)
            shannon_ent = shannon_entropy(cam_discrete)
            entropy_results['shannon'] = shannon_ent
        
        # 2. ê³µê°„ì  ì—”íŠ¸ë¡œí”¼ (ê·¸ë˜ë””ì–¸íŠ¸ ë°©ì‹)
        if 'spatial' in methods:
            # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° (ì¤‘ì•™ ì°¨ë¶„ ë°©ì‹)
            gx = np.zeros_like(cam)
            gy = np.zeros_like(cam)
            
            # ìˆ˜í‰ ê·¸ë˜ë””ì–¸íŠ¸ (Gx) - ì¤‘ì•™ ì°¨ë¶„
            gx[:, 1:-1] = (cam[:, 2:] - cam[:, :-2]) / 2.0
            
            # ìˆ˜ì§ ê·¸ë˜ë””ì–¸íŠ¸ (Gy) - ì¤‘ì•™ ì°¨ë¶„
            gy[1:-1, :] = (cam[2:, :] - cam[:-2, :]) / 2.0
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° (magnitude)
            gradient_magnitude = np.sqrt(gx**2 + gy**2)
            
            # ê° ë°©í–¥ë³„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            gx_ent = shannon_entropy((gx * 255).astype(np.uint8))
            gy_ent = shannon_entropy((gy * 255).astype(np.uint8))
            magnitude_ent = shannon_entropy((gradient_magnitude * 255).astype(np.uint8))
            
            # í‰ê·  ê³µê°„ ì—”íŠ¸ë¡œí”¼ (ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            spatial_ent = 0.4 * gx_ent + 0.4 * gy_ent + 0.2 * magnitude_ent
            entropy_results['spatial'] = spatial_ent
            entropy_results['spatial_directions'] = {
                'horizontal': gx_ent, 
                'vertical': gy_ent, 
                'magnitude': magnitude_ent
            }
        
        # 3. íˆìŠ¤í† ê·¸ë¨ ì—”íŠ¸ë¡œí”¼
        if 'histogram' in methods:
            non_zero_cam = cam.flatten()[cam.flatten() > 0]
            if len(non_zero_cam) > 0:
                activation_ratio = len(non_zero_cam) / len(cam.flatten())
                hist, bins = np.histogram(non_zero_cam, bins=50, density=True)
                hist = hist[hist > 0]
                hist_ent = entropy(hist)
                
                entropy_results['histogram'] = hist_ent
                entropy_results['activation_ratio'] = activation_ratio
                entropy_results['non_zero_count'] = len(non_zero_cam)
            else:
                entropy_results['histogram'] = 0.0
                entropy_results['activation_ratio'] = 0.0
                entropy_results['non_zero_count'] = 0
        
        # 4. ì¡°ê±´ë¶€ ì—”íŠ¸ë¡œí”¼
        if 'conditional' in methods:
            thresholds = [50, 75, 85, 90, 95]
            conditional_ents = {}
            
            for thresh in thresholds:
                threshold_val = np.percentile(cam, thresh)
                active_mask = cam > threshold_val
                inactive_mask = cam <= threshold_val
                
                if np.sum(active_mask) > 0:
                    active_ent = shannon_entropy((cam[active_mask] * 255).astype(np.uint8))
                else:
                    active_ent = 0
                    
                if np.sum(inactive_mask) > 0:
                    inactive_ent = shannon_entropy((cam[inactive_mask] * 255).astype(np.uint8))
                else:
                    inactive_ent = 0
                
                active_ratio = np.sum(active_mask) / cam.size
                conditional_ent = active_ratio * active_ent + (1 - active_ratio) * inactive_ent
                conditional_ents[thresh] = conditional_ent
            
            entropy_results['conditional'] = conditional_ents
        
        return entropy_results
    
    def calculate_cam_bbox_overlap(self, cam: np.ndarray, boxes: np.ndarray, 
                                  names: List[str]) -> Dict:
        """
        CAM í™œì„± ì˜ì—­ê³¼ ê°€ì¥ í° bbox ê°„ì˜ overlap ê³„ì‚° (ì„ê³„ê°’ ì—†ì´ ëª¨ë“  í™œì„±í™” ê°’ í™œìš©)
        
        Args:
            cam: CAM ë°ì´í„°
            boxes: ê²€ì¶œëœ ë°•ìŠ¤ ì¢Œí‘œ
            names: í´ë˜ìŠ¤ëª…ê³¼ ì‹ ë¢°ë„ê°€ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: "car 0.95")
            
        Returns:
            Dict: Overlap ë¶„ì„ ê²°ê³¼
        """
        if len(boxes) == 0:
            return None
        
        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ì¶œ
        class_names = []
        confidences = []
        for name in names:
            # "class_name confidence" í˜•ì‹ì—ì„œ ë¶„ë¦¬
            parts = name.split()
            if len(parts) >= 2:
                class_name = ' '.join(parts[:-1])  # ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ì œì™¸í•œ ëª¨ë“  ë¶€ë¶„ì´ í´ë˜ìŠ¤ëª…
                confidence = float(parts[-1])
            else:
                class_name = name
                confidence = 1.0
            class_names.append(class_name)
            confidences.append(confidence)
        
        # ê°€ì¥ í° bbox ì°¾ê¸°
        areas = []
        for box in boxes:
            x1, y1, x2, y2 = box
            area = (x2 - x1) * (y2 - y1)
            areas.append(area)
        
        largest_idx = np.argmax(areas)
        largest_bbox = boxes[largest_idx]
        largest_area = areas[largest_idx]
        largest_name = class_names[largest_idx]
        largest_confidence = confidences[largest_idx]
        
        # bbox ì •ë³´ ì¶”ì¶œ
        x1, y1, x2, y2 = largest_bbox
        
        # bboxë¥¼ ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
        img_height, img_width = cam.shape
        x1 = max(0, min(int(x1), img_width-1))
        y1 = max(0, min(int(y1), img_height-1))
        x2 = max(0, min(int(x2), img_width-1))
        y2 = max(0, min(int(y2), img_height-1))
        
        # bbox ë§ˆìŠ¤í¬ ìƒì„±
        bbox_mask = np.zeros_like(cam, dtype=bool)
        bbox_mask[y1:y2+1, x1:x2+1] = True
        
        # CAM í™œì„± ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„± (ì„ê³„ê°’ ì—†ì´ ëª¨ë“  í™œì„±í™” ê°’ í™œìš©)
        cam_active_mask = cam > 0  # 0ë³´ë‹¤ í° ëª¨ë“  ê°’ì„ í™œì„± ì˜ì—­ìœ¼ë¡œ ê°„ì£¼
        
        # Overlap ê³„ì‚°
        intersection = np.logical_and(bbox_mask, cam_active_mask)
        union = np.logical_or(bbox_mask, cam_active_mask)
        
        intersection_area = np.sum(intersection)
        union_area = np.sum(union)
        iou = intersection_area / union_area if union_area > 0 else 0
        
        bbox_area = np.sum(bbox_mask)
        cam_active_area = np.sum(cam_active_mask)
        
        cam_coverage = intersection_area / bbox_area if bbox_area > 0 else 0
        bbox_coverage = intersection_area / cam_active_area if cam_active_area > 0 else 0
        
        return {
            'iou': iou,
            'cam_coverage': cam_coverage,
            'bbox_coverage': bbox_coverage,
            'intersection_area': intersection_area,
            'bbox_area': bbox_area,
            'cam_active_area': cam_active_area,
            'union_area': union_area,
            'bbox_coords': (x1, y1, x2, y2),
            'bbox_mask': bbox_mask,
            'cam_active_mask': cam_active_mask,
            'intersection_mask': intersection,
            'largest_bbox_idx': largest_idx,
            'all_areas': areas,
            'largest_class_name': largest_name,
            'largest_confidence': largest_confidence,
            'all_class_names': class_names,
            'all_confidences': confidences,
            # ì‹œê°í™”ë¥¼ ìœ„í•œ ì¶”ê°€ ì •ë³´
            'all_bboxes': boxes.tolist(),  # ëª¨ë“  bbox ì¢Œí‘œ
            'bbox_names': class_names,  # ëª¨ë“  bbox í´ë˜ìŠ¤ëª… (ì‹ ë¢°ë„ ì œì™¸)
            'threshold_info': {
                'threshold': 0.0,
                'threshold_percentile': 0,
                'method': 'no_threshold_all_activations'
            }
        }
    
    def comprehensive_cam_analysis(self, image_path: str, target_layers: Optional[List] = None,
                                 target_layer_index: Optional[int] = None,
                                 save_visualizations: bool = False, output_dir: Optional[str] = None) -> Dict:
        """
        CAMì— ëŒ€í•œ í¬ê´„ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            target_layers: íƒ€ê²Ÿ ë ˆì´ì–´ ë¦¬ìŠ¤íŠ¸
            target_layer_index: íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë ˆì´ì–´ ì‚¬ìš© (0ë¶€í„° ì‹œì‘)
            save_visualizations: ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì—¬ë¶€ (CAM ì´ë¯¸ì§€ ë“±)
            output_dir: ì‹œê°í™” ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (save_visualizations=Trueì¼ ë•Œë§Œ ì‚¬ìš©)
            
        Returns:
            Dict: í¬ê´„ì ì¸ CAM ë¶„ì„ ê²°ê³¼
        """
        print(f"Comprehensive CAM analysis for: {image_path}")
        
        # CAM ìƒì„± (íƒ€ê²Ÿ ë ˆì´ì–´ê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ì €ì¥ëœ íƒ€ê²Ÿ ë ˆì´ì–´ ì‚¬ìš©)
        if target_layers is None:
            target_layers = self.get_target_layers(target_layer_index)
        
        cam_result = self.generate_cam(image_path, target_layers, target_layer_index)
        if cam_result is None:
            return None
        
        grayscale_cam = cam_result['grayscale_cam']
        
        # 1. ê¸°ë³¸ í†µê³„ (Percentileê³¼ Skewness ë¶„ì„ í¬í•¨)
        cam_stats = self.calculate_cam_statistics(grayscale_cam)
        
        # 2. Adaptive ì“°ë ˆìŠ¤í™€ë”©
        adaptive_cam = self.adaptive_thresholding(grayscale_cam)
        
        # 3. ìµœì  ì„ê³„ê°’ ì°¾ê¸° ë° Connected Components ë¶„ì„
        optimal_threshold_info = self.find_optimal_threshold_for_components(grayscale_cam)
        components_analysis = self.analyze_connected_components(grayscale_cam, optimal_threshold_info['optimal_percentile'])
        
        # 4. Centroid ê³„ì‚°
        centroids = self.calculate_cam_centroids(grayscale_cam)
        
        # 5. ì—”íŠ¸ë¡œí”¼ ë¶„ì„
        entropy_results = self.calculate_cam_entropy(grayscale_cam)
        
        # 6. ê°ì²´ ê²€ì¶œ ë° Overlap ë¶„ì„
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        rgb_img = cv2.imread(cam_result['image_path'])
        results = self.model(rgb_img)
        boxes, colors, names = self.parse_detections(results)
        
        overlap_results = None
        if len(boxes) > 0:
            overlap_results = self.calculate_cam_bbox_overlap(grayscale_cam, boxes, names)
        
        # ì‹œê°í™” ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­) - ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥
        visualization_paths = {}
        if save_visualizations and output_dir:
            os.makedirs(output_dir, exist_ok=True)
            filename = os.path.basename(image_path)
            name, ext = os.path.splitext(filename)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥ (ì‹¤ì œ ì´ë¯¸ì§€ëŠ” í•„ìš”ì‹œ ë¡œë“œ)
            visualization_paths['original_image'] = image_path
            
            print(f"Original image path saved: {image_path}")
        
        # CAM ë°ì´í„°ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥ (ìºì‹œ ë””ë ‰í† ë¦¬ ì•ˆì—)
        cam_output_dir = os.path.join(output_dir, 'cam_data') if output_dir else None
        cam_file_path = None
        
        if cam_output_dir:
            # ì›ë³¸ CAM ë°ì´í„° ì €ì¥ (ì••ì¶• ì—†ìŒ)
            cam_file_path = self.save_cam_data_original(image_path, grayscale_cam, cam_output_dir)
        
        # ê²°ê³¼ í†µí•© (ìºì‹œì— ì €ì¥ë  ë°ì´í„°) - CAM íŒŒì¼ ê²½ë¡œë§Œ ì €ì¥
        comprehensive_result = {
            'image_path': image_path,
            'cam_file_path': cam_file_path,  # ì›ë³¸ CAM íŒŒì¼ ê²½ë¡œ
            'target_layers': [str(layer) for layer in target_layers] if target_layers else [],
            'target_layer_index': self.target_layer_index,  # ì €ì¥ëœ íƒ€ê²Ÿ ë ˆì´ì–´ ì¸ë±ìŠ¤
            'cam_stats': cam_stats,
            'adaptive_thresholding': {
                'percentile': 85,
                'threshold': float(np.percentile(grayscale_cam, 85)),
                'active_ratio': float(np.sum(grayscale_cam > np.percentile(grayscale_cam, 85)) / grayscale_cam.size * 100)
            },
            'components_analysis': {
                'threshold': components_analysis['threshold'],
                'active_pixels': components_analysis['active_pixels'],
                'active_ratio': components_analysis['active_ratio'],
                'num_components': components_analysis['num_components'],
                'size_stats': components_analysis.get('size_stats', {}),
                'optimal_threshold_info': optimal_threshold_info  # ìµœì  ì„ê³„ê°’ ì •ë³´ ì €ì¥
            },
            'centroids': centroids,
            'entropy_results': entropy_results,
            'detection_results': {
                'boxes': boxes.tolist() if len(boxes) > 0 else [],
                'names': names
            },
            'overlap_results': overlap_results,
            'visualization_paths': visualization_paths if save_visualizations else {},
            'analysis_timestamp': datetime.now().isoformat(),
            'model_name': self.model_name
        }
        
        return comprehensive_result

    def get_cache_size_info(self, comprehensive_result: Dict) -> Dict:
        """
        ìºì‹œ í¬ê¸° ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            comprehensive_result: í¬ê´„ì ì¸ ë¶„ì„ ê²°ê³¼
            
        Returns:
            Dict: ìºì‹œ í¬ê¸° ì •ë³´
        """
        import sys
        import json
        
        # ë”•ì…”ë„ˆë¦¬ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ í¬ê¸° ì¸¡ì •
        try:
            json_str = json.dumps(comprehensive_result)
            size_bytes = len(json_str.encode('utf-8'))
            size_mb = size_bytes / (1024 * 1024)
            
            # ê° í‚¤ë³„ í¬ê¸° ë¶„ì„
            key_sizes = {}
            for key, value in comprehensive_result.items():
                if key == 'grayscale_cam':
                    # CAM ë°ì´í„°ëŠ” ë§¤ìš° í´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
                    if isinstance(value, list):
                        cam_size = len(value) * 4  # float32 = 4 bytes
                        key_sizes[key] = f"{cam_size / (1024*1024):.2f} MB"
                    else:
                        key_sizes[key] = "N/A"
                else:
                    try:
                        key_json = json.dumps(value)
                        key_size = len(key_json.encode('utf-8'))
                        key_sizes[key] = f"{key_size / 1024:.2f} KB"
                    except:
                        key_sizes[key] = "N/A"
            
            return {
                'total_size_mb': size_mb,
                'total_size_bytes': size_bytes,
                'key_sizes': key_sizes
            }
            
        except Exception as e:
            return {
                'error': str(e),
                'total_size_mb': 0,
                'key_sizes': {}
            }


    
    def save_cam_data_original(self, image_path: str, grayscale_cam: np.ndarray, output_dir: str) -> str:
        """
        CAM ë°ì´í„°ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥í•©ë‹ˆë‹¤ (numpy .npy í˜•ì‹)
        
        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            grayscale_cam: CAM ë°ì´í„°
            output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬
            
        Returns:
            str: ì €ì¥ëœ CAM íŒŒì¼ ê²½ë¡œ
        """
        import os
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„± (.npy í™•ì¥ì)
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        cam_file = os.path.join(output_dir, f"{base_name}_cam_original.npy")
        
        # numpy .npy í˜•ì‹ìœ¼ë¡œ ì €ì¥
        np.save(cam_file, grayscale_cam)
        
        # ë””ë²„ê¹…: ì €ì¥ëœ CAM ë°ì´í„° ì •ë³´ ì¶œë ¥
        print(f"    ğŸ” Saved CAM data: shape={grayscale_cam.shape}, dtype={grayscale_cam.dtype}")
        print(f"    ğŸ” Saved CAM data stats: min={grayscale_cam.min():.6f}, max={grayscale_cam.max():.6f}, mean={grayscale_cam.mean():.6f}")
        
        # í¬ê¸° ì •ë³´ ì¶œë ¥
        original_size = grayscale_cam.nbytes
        file_size = os.path.getsize(cam_file)
        compression_ratio = (1 - file_size / original_size) * 100
        
        print(f"CAM data original: {original_size/1024:.1f}KB â†’ {file_size/1024:.1f}KB ({compression_ratio:.1f}% reduction)")
        print(f"Saved to: {cam_file}")
        
        return cam_file
    

    
    def load_cam_data_original(self, cam_file_path: str) -> np.ndarray:
        """
        ì›ë³¸ CAM ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤ (numpy .npy í˜•ì‹)
        
        Args:
            cam_file_path: CAM íŒŒì¼ ê²½ë¡œ
            
        Returns:
            np.ndarray: ì›ë³¸ CAM ë°ì´í„°
        """
        # numpy .npy í˜•ì‹ì—ì„œ ë¡œë“œ
        loaded_cam = np.load(cam_file_path)
        
        # ë””ë²„ê¹…: ë¡œë“œëœ CAM ë°ì´í„° ì •ë³´ ì¶œë ¥
        print(f"    ğŸ” Loaded CAM data: shape={loaded_cam.shape}, dtype={loaded_cam.dtype}")
        print(f"    ğŸ” Loaded CAM data stats: min={loaded_cam.min():.6f}, max={loaded_cam.max():.6f}, mean={loaded_cam.mean():.6f}")
        
        return loaded_cam