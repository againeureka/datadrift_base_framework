#!/usr/bin/env python3
"""
ìºì‹œ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
ë°ì´í„°ì…‹ë³„ ìºì‹œë¥¼ ê´€ë¦¬í•˜ëŠ” ëª…ë ¹ì¤„ ë„êµ¬ì…ë‹ˆë‹¤.
"""

import argparse
import os
import sys
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ìºì‹œ ë§¤ë‹ˆì € import (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
from .cache_manager import get_cache_manager, get_cached_analysis_data, save_analysis_data

def main():
    parser = argparse.ArgumentParser(
        description='ìºì‹œ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python cache_utils/cache_utils.py info /path/to/dataset
  python cache_utils/cache_utils.py list /path/to/dataset
  python cache_utils/cache_utils.py clear /path/to/dataset
  python cache_utils/cache_utils.py invalidate html_report /path/to/dataset
        """
    )
    
    parser.add_argument('command', choices=['info', 'list', 'clear', 'invalidate'],
                       help='ì‹¤í–‰í•  ëª…ë ¹')
    parser.add_argument('directory', nargs='?', help='ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (ì„ íƒì‚¬í•­)')
    parser.add_argument('--identifier', help='ë¬´íš¨í™”í•  ìºì‹œ ì‹ë³„ì (invalidate ëª…ë ¹ì—ì„œ ì‚¬ìš©)')
    parser.add_argument('--content-type', default='html', 
                       choices=['html', 'analysis'], help='ìºì‹œ ì»¨í…ì¸  íƒ€ì…')
    
    args = parser.parse_args()
    
    # ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©
    if not args.directory:
        args.directory = os.getcwd()
    
    if not os.path.exists(args.directory):
        print(f"ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.directory}")
        sys.exit(1)
    
    # ìºì‹œ ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
    cache_manager = get_cache_manager(args.directory)
    
    if args.command == 'info':
        show_cache_info(cache_manager, args.directory)
    
    elif args.command == 'list':
        list_cache_files(cache_manager, args.directory)
    
    elif args.command == 'clear':
        clear_cache(cache_manager, args.directory)
    
    elif args.command == 'invalidate':
        if not args.identifier:
            print("ì˜¤ë¥˜: invalidate ëª…ë ¹ì—ëŠ” --identifierê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            sys.exit(1)
        invalidate_cache(cache_manager, args.identifier, args.content_type, args.directory)

def show_cache_info(cache_manager, directory):
    """ìºì‹œ ì •ë³´ í‘œì‹œ"""
    info = cache_manager.get_cache_info()
    
    print(f"ğŸ“ ìºì‹œ ë””ë ‰í† ë¦¬: {info['cache_dir']}")
    print(f"ğŸ“Š ì´ íŒŒì¼ ìˆ˜: {info['total_files']}")
    print(f"ğŸ’¾ ì´ í¬ê¸°: {info['total_size_mb']} MB")
    print(f"ğŸ”’ ìµœëŒ€ í¬ê¸°: {info['max_size_mb']} MB")
    print(f"â° ë§Œë£Œ ê¸°ê°„: {info['expiry_days']}ì¼")
    
    # ë¶„ì„ ë°ì´í„° í™•ì¸
    cached_data = get_cached_analysis_data(directory, "image_analysis")
    if cached_data:
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë°ì´í„°: {len(cached_data)}ê°œ íŒŒì¼")
    else:
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë°ì´í„°: ì—†ìŒ")

def list_cache_files(cache_manager, directory):
    """ìºì‹œ íŒŒì¼ ëª©ë¡ í‘œì‹œ"""
    cache_dir = Path(cache_manager.cache_dir)
    
    if not cache_dir.exists():
        print("ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    cache_files = list(cache_dir.glob("*.cache"))
    
    if not cache_files:
        print("ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“‹ ìºì‹œ íŒŒì¼ ëª©ë¡ ({len(cache_files)}ê°œ):")
    print("-" * 80)
    
    for cache_file in sorted(cache_files):
        size = cache_file.stat().st_size
        size_mb = size / (1024 * 1024)
        modified_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ í™•ì¸
        metadata_file = cache_file.with_name(f"{cache_file.stem}_meta.json")
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r') as f:
                    import json
                    metadata = json.load(f)
                    content_type = metadata.get('content_type', 'unknown')
                    created_time = metadata.get('created_time', 'unknown')
            except:
                content_type = 'unknown'
                created_time = 'unknown'
        else:
            content_type = 'unknown'
            created_time = 'unknown'
        
        print(f"ğŸ“„ {cache_file.name}")
        print(f"   í¬ê¸°: {size_mb:.2f} MB")
        print(f"   íƒ€ì…: {content_type}")
        print(f"   ìƒì„±: {created_time}")
        print(f"   ìˆ˜ì •: {modified_time}")
        print()

def clear_cache(cache_manager, directory):
    """ìºì‹œ ì •ë¦¬"""
    print(f"ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬ ì¤‘: {directory}")
    
    result = cache_manager.clear_all_cache()
    
    if result:
        print("âœ… ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def invalidate_cache(cache_manager, identifier, content_type, directory):
    """íŠ¹ì • ìºì‹œ ë¬´íš¨í™”"""
    print(f"ğŸ”„ ìºì‹œ ë¬´íš¨í™” ì¤‘: {identifier} ({content_type})")
    
    result = cache_manager.invalidate_cache(identifier, content_type)
    
    if result:
        print("âœ… ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ë¬´íš¨í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ìºì‹œ ë¬´íš¨í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    main() 